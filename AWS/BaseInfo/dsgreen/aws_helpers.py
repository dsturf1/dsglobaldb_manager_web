
import geopandas as gpd
import pandas as pd
import json
import os
import tempfile
import boto3
import fiona
import glob

_Bucket='dsgeousergrp'
_GRP_Name = 'dsgeoadmin'

def load_all_json_from_prefix(bucket_name:str , prefix: str):
    s3 = boto3.client('s3')
    result_dict = {}

    # 1. prefix ê²½ë¡œ ì•„ë˜ì˜ ëª¨ë“  ê°ì²´ ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
    response = s3.list_objects_v2(Bucket=bucket_name, Prefix=prefix)

    if 'Contents' not in response:
        print("No files found.")
        return result_dict

    for obj in response['Contents']:
        key = obj['Key']
        if key.endswith('.json'):
            try:
                content_object = s3.get_object(Bucket=bucket_name, Key=key)
                file_content = content_object['Body'].read().decode('utf-8')
                json_data = json.loads(file_content)

                # íŒŒì¼ëª…ì—ì„œ .json ì œê±°í•˜ê³  ë”•ì…”ë„ˆë¦¬ keyë¡œ ì‚¬ìš©
                filename = key.split('/')[-1].replace('.json', '')
                result_dict[filename] = json_data

            except Exception as e:
                print(f"Error reading {key}: {e}")

    return result_dict
  
def saveJson(gdf, filename):

  with fiona.Env(OSR_WKT_FORMAT="WKT2_2018"):
    gdf.to_file(filename, driver='GeoJSON')

def upload2S3(filename, course_id, bucket_name: str, __GRP_Name: str):
  import boto3
  s3 = boto3.client('s3')
  json_content_ = json.load(open(filename, encoding="utf8"))
  s3.put_object(Body=json.dumps(json_content_).encode('utf-8'),Bucket=bucket_name,Key=__GRP_Name +'/coursegeojson/' +course_id+'.json')

def fromS3AsGDF(_course_id, bucket_name: str, __GRP_Name: str):
  import boto3
  s3 = boto3.client('s3')
  #S3ë¡œë¶€í„° ì „ë©´ geojsoní™”ì¼ ë‹¤ìš´
  content_object = s3.get_object(Bucket=bucket_name,Key=__GRP_Name +'/coursegeojson/' +_course_id+'.json')
  file_content = content_object['Body'].read().decode('utf-8')
  json_content = json.loads(file_content)
  gdf = gpd.GeoDataFrame.from_features(json_content['features'], crs=int(4326))

  return gdf

def AreafromS3AsGDF(_course_id, bucket_name: str, __GRP_Name: str):
  import boto3
  s3 = boto3.client('s3')
  #S3ë¡œë¶€í„° ì „ë©´ geojsoní™”ì¼ ë‹¤ìš´
  content_object = s3.get_object(Bucket=bucket_name,Key=__GRP_Name +'/geojson/' +_course_id+'.json')
  file_content = content_object['Body'].read().decode('utf-8')
  json_content = json.loads(file_content)
  gdf = gpd.GeoDataFrame.from_features(json_content['features'], crs=int(4326))

  return gdf

def cal_bearing(row):
  import pyproj
  geodesic = pyproj.Geod(ellps='WGS84')
  
  if row.Type == 'í™€ì˜ì—­':
    bearing = geodesic.inv(row.greencenter.x, row.greencenter.y, row.center.x, row.center.y)[0]
  else:
    bearing = 0.0

  return bearing


def download_s3_folder(bucket_name: str, local_dir: str, s3_prefix: str = ''):
    """
    Download all files from an S3 bucket or folder to a local directory.

    Args:
        bucket_name: Name of the S3 bucket
        local_dir: Local directory path to download files to
        s3_prefix: S3 prefix/folder path (e.g., 'folder/subfolder/').
                   Default is '' which downloads the entire bucket.
    """
    import os
    s3 = boto3.client('s3')

    # Ensure local directory exists
    if not os.path.exists(local_dir):
        os.makedirs(local_dir)

    # List all objects with the given prefix
    paginator = s3.get_paginator('list_objects_v2')

    for page in paginator.paginate(Bucket=bucket_name, Prefix=s3_prefix):
        if 'Contents' not in page:
            print(f"No files found in {s3_prefix}")
            return

        for obj in page['Contents']:
            key = obj['Key']

            # Skip if it's just the folder itself
            if key.endswith('/'):
                continue

            # Get relative path from prefix
            relative_path = key[len(s3_prefix):].lstrip('/')
            local_file_path = os.path.join(local_dir, relative_path)

            # Create subdirectories if needed
            local_file_dir = os.path.dirname(local_file_path)
            if local_file_dir and not os.path.exists(local_file_dir):
                os.makedirs(local_file_dir)

            # Download file
            # print(f"Downloading: {key} -> {local_file_path}")
            s3.download_file(bucket_name, key, local_file_path)

    print(f"Download {len(page['Contents'])} complete: {local_dir}")
    

def load_s3_json(bucket_name: str, s3_key: str, src_folder: str = None):
  """
  Download a JSON file from S3 to specified folder or temporary location and return its content.
  
  Args:
    bucket_name: Name of the S3 bucket
    s3_key: Full S3 key path to the JSON file (e.g., 'folder/file.json')
    src_folder: Optional folder path to save the file. If None, uses temporary file.
  
  Returns:
    dict: Parsed JSON content
  """
  
  s3 = boto3.client('s3')
  
  if src_folder:
    # Create folder if it doesn't exist
    if not os.path.exists(src_folder):
      os.makedirs(src_folder)
    
    # Create file path preserving S3 structure
    local_path = os.path.join(src_folder, s3_key.replace('/', os.sep))
    local_dir = os.path.dirname(local_path)
    
    if not os.path.exists(local_dir):
      os.makedirs(local_dir)
    
    try:
      # Download file to specified location
      print(f"Downloading: {s3_key} from bucket: {bucket_name}")
      s3.download_file(bucket_name, s3_key, local_path)
      
      # Read and parse JSON
      with open(local_path, 'r', encoding='utf-8') as f:
        json_content = json.load(f)
      
      print(f"Successfully loaded and saved JSON to {local_path}")
      return json_content
      
    except Exception as e:
      print(f"Error downloading file: {e}")
      raise
  else:
    print('src_folder must be provided to save the file.')
    return None
  
def save_s3_json(data, bucket_name, s3_key, src_folder):
  """Save JSON data to S3 bucket"""
  s3_client = boto3.client('s3')
  
  # Create local file path for backup
  local_file_path = os.path.join(src_folder, s3_key)
  os.makedirs(os.path.dirname(local_file_path), exist_ok=True)
  
  # Save JSON to local file first
  with open(local_file_path, 'w', encoding='utf8') as f:
    json.dump(data, f, ensure_ascii=False, indent=2)
  
  # Upload to S3
  try:
    s3_client.upload_file(local_file_path, bucket_name, s3_key)
    print(f"Successfully saved to s3://{bucket_name}/{s3_key}")
  except ClientError as e:
    print(f"Error uploading to S3: {e}")
    




def copy_files_from_downloaded2upload(src_folder, dest_folder):
  """
  Copy files from source folder to destination folder, handling subdirectories.
  """
  import shutil
  import os
  
  if not os.path.exists(dest_folder):
    os.makedirs(dest_folder)
  
  if not os.path.exists(src_folder):
    print(f"Source folder does not exist: {src_folder}")
    return
  
  for root, dirs, files in os.walk(src_folder):
    # Calculate relative path from source folder
    rel_path = os.path.relpath(root, src_folder)
    dest_dir = os.path.join(dest_folder, rel_path)
    
    # Create destination directory if it doesn't exist
    if not os.path.exists(dest_dir):
      os.makedirs(dest_dir)
    
    # Copy each file
    for file in files:
      src_file = os.path.join(root, file)
      dest_file = os.path.join(dest_dir, file)
      
      try:
        shutil.copy2(src_file, dest_file)
      except Exception as e:
        print(f"Error copying {src_file}: {e}")
        
    print(f"{len(files)} files copied from {src_folder} to {dest_folder} successfully.")
    
def fix_korean_json(folder):
  for f in os.listdir(folder):
    if f.endswith('.json'):
      path = os.path.join(folder, f)
      data = json.load(open(path, encoding='utf-8'))
      json.dump(data, open(path, 'w', encoding='utf-8'), ensure_ascii=False, indent=2)

def load_course_from_s3(bucket_name: str, course_id: str, grp_name: str = 'dsgeoadmin'):
  """
  S3ì—ì„œ ì½”ìŠ¤ GeoJSON ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì—¬ JSON dictë¡œ ë°˜í™˜.

  Args:
    bucket_name: S3 ë²„í‚· ì´ë¦„ (ì˜ˆ: 'dsgeousergrp')
    course_id: ì½”ìŠ¤ ID (ì˜ˆ: 'TGC001')
    grp_name: ê·¸ë£¹ í´ë”ëª… (ê¸°ë³¸ê°’: 'dsgeoadmin')

  Returns:
    dict: GeoJSON í˜•ì‹ì˜ ì½”ìŠ¤ ë°ì´í„°
    
  # ì½”ìŠ¤ ë°ì´í„° ë¡œë“œ
data = load_course_from_s3('dsgeousergrp', 'TGC001')

# grp_name ì§€ì • ê°€ëŠ¥
data = load_course_from_s3('dsgeousergrp', 'TGC001', grp_name='dsgeoadmin')
  """
  s3 = boto3.client('s3')
  s3_key = f'{grp_name}/coursegeojson/{course_id}.json'

  try:
    content_object = s3.get_object(Bucket=bucket_name, Key=s3_key)
    file_content = content_object['Body'].read().decode('utf-8')
    json_content = json.loads(file_content)
    return json_content
  except Exception as e:
    print(f"Error loading {s3_key} from {bucket_name}: {e}")
    return None

def load_baseinfo_from_s3(bucket_name: str, file_name: str, subfolder: str = 'common'):
  """
  S3ì—ì„œ baseinfo JSON ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì—¬ ë°˜í™˜.

  Args:
    bucket_name: S3 ë²„í‚· ì´ë¦„ (ì˜ˆ: 'dsgeousergrp')
    file_name: íŒŒì¼ëª… (ì˜ˆ: 'course_info.json')
    subfolder: baseinfo í•˜ìœ„ í´ë” (ê¸°ë³¸ê°’: 'common', ë˜ëŠ” 'geo')

  Returns:
    dict: JSON ë°ì´í„°

  Example:
    data = load_baseinfo_from_s3('dsgeousergrp', 'course_info.json')
    data = load_baseinfo_from_s3('dsgeousergrp', 'area_def.json', subfolder='geo')
  """
  s3 = boto3.client('s3')
  s3_key = f'{subfolder}/{file_name}'

  try:
    content_object = s3.get_object(Bucket=bucket_name, Key=s3_key)
    file_content = content_object['Body'].read().decode('utf-8')
    json_content = json.loads(file_content)
    return json_content
  except Exception as e:
    print(f"Error loading {s3_key} from {bucket_name}: {e}")
    return None

def get_location_from_gps(crs_geojson: dict, gps: dict) -> list:
  """
  GPS ì¢Œí‘œë¥¼ ê¸°ë°˜ìœ¼ë¡œ crs_geojsonì˜ featuresì—ì„œ í•´ë‹¹ ìœ„ì¹˜ì˜ ëª¨ë“  location ì •ë³´ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜.

  Args:
    crs_geojson: ì½”ìŠ¤ GeoJSON ë°ì´í„° (features í¬í•¨)
    gps: GPS ì •ë³´ dict (longitude, latitude í•„ìˆ˜)
         ì˜ˆ: {'longitude': Decimal('128.443'), 'latitude': Decimal('35.996'), ...}

  Returns:
    list: location ì •ë³´ ë¦¬ìŠ¤íŠ¸ [{'Hole': int, 'Area': str, 'Client': str, 'Course': str}, ...]
          í•´ë‹¹ ìœ„ì¹˜ë¥¼ ì°¾ì§€ ëª»í•˜ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜

  Example:
    locations = get_location_from_gps(crs_geojson, gps)
  """
  from shapely.geometry import Point, shape

  lng = float(gps.get('longitude', 0))
  lat = float(gps.get('latitude', 0))

  if lng == 0 or lat == 0:
    return []

  point = Point(lng, lat)
  results = []

  for feature in crs_geojson.get('features', []):
    try:
      polygon = shape(feature['geometry'])
      if polygon.contains(point):
        props = feature.get('properties', {})
        results.append({
          'Hole': int(props.get('Hole', 0)) if props.get('Hole') is not None else 0,
          'Area': props.get('Type', ''),
          'Client': props.get('Client', ''),
          'Course': props.get('Course', '')
        })
    except Exception:
      continue

  return results

def get_best_location_from_gps(crs_geojson: dict, gps: dict, priority: list = None) -> dict:
  """
  GPS ì¢Œí‘œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìš°ì„ ìˆœìœ„ì— ë”°ë¼ ê°€ì¥ ì í•©í•œ location ì •ë³´ë¥¼ ë°˜í™˜.

  Args:
    crs_geojson: ì½”ìŠ¤ GeoJSON ë°ì´í„° (features í¬í•¨)
    gps: GPS ì •ë³´ dict (longitude, latitude í•„ìˆ˜)
    priority: Area ìš°ì„ ìˆœìœ„ ë¦¬ìŠ¤íŠ¸ (ê¸°ë³¸ê°’: ['í™€ì˜ì—­', 'ê·¸ë¦°', 'ì§€ì—­', 'ì½”ìŠ¤', 'ì „ë©´'])

  Returns:
    dict: ìš°ì„ ìˆœìœ„ê°€ ê°€ì¥ ë†’ì€ location ì •ë³´ {'Hole': int, 'Area': str, 'Client': str, 'Course': str}
          í•´ë‹¹ ìœ„ì¹˜ë¥¼ ì°¾ì§€ ëª»í•˜ë©´ None ë°˜í™˜

  Example:
    location = get_best_location_from_gps(crs_geojson, gps)
    location = get_best_location_from_gps(crs_geojson, gps, priority=['ê·¸ë¦°', 'í™€ì˜ì—­', 'ì½”ìŠ¤'])
  """
  if priority is None:
    priority = ['í™€ì˜ì—­', 'ê·¸ë¦°', 'ì§€ì—­', 'ì½”ìŠ¤', 'ì „ë©´']

  locations = get_location_from_gps(crs_geojson, gps)

  if not locations:
    return None

  for area_type in priority:
    for loc in locations:
      if loc.get('Area') == area_type:
        return loc

  # ìš°ì„ ìˆœìœ„ì— ì—†ëŠ” Areaê°€ ìˆìœ¼ë©´ ì²«ë²ˆì§¸ ë°˜í™˜
  return locations[0] if locations else None

def clean_and_normalize_features(features, default_props, mapdscourseid=None):
    """
    GeoJSON featuresì˜ propertiesë¥¼ ì •ë¦¬í•˜ê³  ì •ê·œí™”í•©ë‹ˆë‹¤.
    
    1. default_propsì— ì •ì˜ëœ í‚¤ë§Œ ìœ ì§€
    2. ëˆ„ë½ëœ í‚¤ëŠ” ê¸°ë³¸ê°’ìœ¼ë¡œ ì±„ì›€
    3. mapdscourseidê°€ íŒŒë¼ë¯¸í„°ë¡œ ì£¼ì–´ì§€ë©´ ëª¨ë“  featureì— ì ìš©
       ì—†ìœ¼ë©´ ê°™ì€ Clientì˜ ë‹¤ë¥¸ featureì—ì„œ ì°¾ì•„ì„œ ì±„ì›€
    4. íƒ€ì…ì´ ë§ì§€ ì•Šìœ¼ë©´ ì˜¬ë°”ë¥¸ íƒ€ì…ìœ¼ë¡œ ë³€í™˜
    
    Args:
        features: GeoJSON features ë¦¬ìŠ¤íŠ¸
        default_props: ê¸°ë³¸ properties ë”•ì…”ë„ˆë¦¬
        mapdscourseid: ëª¨ë“  featureì— ì ìš©í•  mapdscourseid (ì„ íƒì‚¬í•­)
    """
    # Clientë³„ mapdscourseid ë§¤í•‘ ìƒì„± (mapdscourseid íŒŒë¼ë¯¸í„°ê°€ ì—†ì„ ë•Œë§Œ ì‚¬ìš©)
    client_to_courseid = {}
    if not mapdscourseid:
        for feature in features:
            props = feature.get('properties', {})
            client = props.get('Client', '')
            courseid = props.get('mapdscourseid')
            if client and courseid:
                client_to_courseid[client] = courseid
    
    for feature in features:
        if 'properties' not in feature:
            continue
            
        current_props = feature['properties']
        cleaned_props = {}
        
        # 1. default_propsì˜ í‚¤ë§Œ ìœ ì§€í•˜ê³  ê¸°ë³¸ê°’ ì±„ìš°ê¸°
        for key, default_value in default_props.items():
            if key in current_props:
                value = current_props[key]
                
                # 2. íƒ€ì… ë³€í™˜
                expected_type = type(default_value)
                if not isinstance(value, expected_type):
                    try:
                        if expected_type == list:
                            if isinstance(value, str):
                                value = json.loads(value)
                            else:
                                value = list(value) if value else default_value.copy()
                        elif expected_type == float:
                            value = float(value)
                        elif expected_type == int:
                            value = int(value)
                        elif expected_type == str:
                            value = str(value)
                    except (ValueError, TypeError, json.JSONDecodeError):
                        value = default_value.copy() if isinstance(default_value, list) else default_value
                
                cleaned_props[key] = value
            else:
                # ê¸°ë³¸ê°’ ì‚¬ìš©
                cleaned_props[key] = default_value.copy() if isinstance(default_value, list) else default_value
        
        # 3. mapdscourseid ì²˜ë¦¬
        if mapdscourseid:
            # íŒŒë¼ë¯¸í„°ë¡œ ë°›ì€ ê°’ìœ¼ë¡œ ê°•ì œ ì„¤ì •
            cleaned_props['mapdscourseid'] = mapdscourseid
        elif not cleaned_props.get('mapdscourseid'):
            # ê°™ì€ Clientì—ì„œ ì°¾ê¸°
            client = cleaned_props.get('Client', '')
            if client and client in client_to_courseid:
                cleaned_props['mapdscourseid'] = client_to_courseid[client]
        
        feature['properties'] = cleaned_props
    
    print(f"Processed {len(features)} features")
    print(f"Properties keys: {list(default_props.keys())}")

    return features

def clean_and_normalize_json_file(file_path, default_props, mapdscourseid=None):
    """
    JSON íŒŒì¼ì„ ì½ì–´ì„œ propertiesë¥¼ ì •ë¦¬í•˜ê³  ì €ì¥í•©ë‹ˆë‹¤.
    
    Args:
        file_path: JSON íŒŒì¼ ê²½ë¡œ
        default_props: ê¸°ë³¸ properties ë”•ì…”ë„ˆë¦¬
        mapdscourseid: ëª¨ë“  featureì— ì ìš©í•  mapdscourseid (ì„ íƒì‚¬í•­)
    """
    with open(file_path, 'r', encoding='utf8') as f:
        json_content = json.load(f)
    
    features = clean_and_normalize_features(json_content['features'], default_props, mapdscourseid)

    with open(file_path, 'w', encoding='utf8') as f:
        json.dump(json_content, f, ensure_ascii=False, indent=2)

    print(f"Updated: {file_path} ({len(features)} features)")
    
def download_baseinfo(base_folder):
    """
    S3ì—ì„œ baseinfo íŒŒì¼ë“¤ì„ ë‹¤ìš´ë¡œë“œí•˜ê³  í•œê¸€ ì¸ì½”ë”©ì„ ìˆ˜ì •í•©ë‹ˆë‹¤.

    Args:
        base_folder: ë‹¤ìš´ë¡œë“œí•  ë¡œì»¬ í´ë” ê²½ë¡œ
    """
    prefixes = ['common/', 'geo/', 'outrecord/', 'work/']
    for prefix in prefixes:
        download_s3_folder(bucket_name='dsbaseinfo', s3_prefix=prefix, local_dir=base_folder+'/'+prefix)
        fix_korean_json(base_folder+'/'+prefix)

def download_course_geojson(grp_name, geojson_folder):
  

    """
    S3ì—ì„œ course geojson íŒŒì¼ë“¤ì„ ë‹¤ìš´ë¡œë“œí•˜ê³  í•œê¸€ ì¸ì½”ë”©ì„ ìˆ˜ì •í•©ë‹ˆë‹¤.

    Args:
        grp_name: ê·¸ë£¹ ì´ë¦„ (ì˜ˆ: 'dsgeoadmin')
        geojson_folder: ë‹¤ìš´ë¡œë“œí•  ë¡œì»¬ í´ë” ê²½ë¡œ
    """
    download_s3_folder(bucket_name='dsgeousergrp', s3_prefix=grp_name+'/coursegeojson/', local_dir=geojson_folder)
    fix_korean_json(geojson_folder)

def updateMGCbaseinfoFromFile(out_folder):
    """
    out_folderì—ì„œ mapdscourse_info.json íŒŒì¼ì„ ì°¾ì•„ S3ì— ì—…ë¡œë“œí•©ë‹ˆë‹¤.
    
    Args:
        out_folder: ToUpload í´ë” ê²½ë¡œ
    """
    baseinfo_path = os.path.join(out_folder, 'baseinfo')
    file_list = glob.glob(os.path.join(baseinfo_path, '**', '*'), recursive=True)
    file_list = [f for f in file_list if os.path.isfile(f) and ('mapcourse_info.json' in f)]
    
    print(f"Total mapdscourse_info.json files found: {len(file_list)}")
    for file in file_list:
        print(file)
    
    # Upload files to S3
    s3_client = boto3.client('s3')
    bucket_name = 'dsbaseinfo'
    
    for file in file_list:
        relative_path = os.path.relpath(file, baseinfo_path)
        s3_key = relative_path.replace('\\', '/')
        
        try:
            s3_client.upload_file(file, bucket_name, s3_key)
            print(f"Uploaded: {file} -> s3://{bucket_name}/{s3_key}")
        except ClientError as e:
            print(f"Error uploading {file}: {e}")


def updateTGCbaseinfoFromFile(out_folder):
    """
    out_folderì—ì„œ mapcourse_info.json íŒŒì¼ì„ ì°¾ì•„ S3ì— ì—…ë¡œë“œí•©ë‹ˆë‹¤.

    Args:
        out_folder: ToUpload í´ë” ê²½ë¡œ
    """
    baseinfo_path = os.path.join(out_folder, 'baseinfo')
    file_list = glob.glob(os.path.join(baseinfo_path, '**', '*'), recursive=True)
    file_list = [f for f in file_list if os.path.isfile(f) and ('mapdscourse_info.json' in f)]

    print(f"Total mapcourse_info.json files found: {len(file_list)}")
    for file in file_list:
        print(file)

    # Upload files to S3
    s3_client = boto3.client('s3')
    bucket_name = 'dsbaseinfo'

    for file in file_list:
        relative_path = os.path.relpath(file, baseinfo_path)
        s3_key = relative_path.replace('\\', '/')

        try:
            s3_client.upload_file(file, bucket_name, s3_key)
            print(f"Uploaded: {file} -> s3://{bucket_name}/{s3_key}")
        except ClientError as e:
            print(f"Error uploading {file}: {e}")


import re
from botocore.exceptions import ClientError

def load_default_feature_properties(file_path: str = './sample_cleanup/default_feature_properties.json') -> dict:
    """
    GeoJSON featureì˜ ê¸°ë³¸ properties í…œí”Œë¦¿ì„ ë¡œë“œí•©ë‹ˆë‹¤.

    Args:
        file_path: JSON íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: './sample_cleanup/default_feature_properties.json')

    Returns:
        dict: ê¸°ë³¸ properties ë”•ì…”ë„ˆë¦¬

    Example:
        default_props = load_default_feature_properties()
    """
    with open(file_path, 'r', encoding='utf-8') as f:
        return json.load(f)


def get_available_dates(src_folder: str) -> list:
    """
    Downloaded í´ë”ì—ì„œ baseinfoì™€ geojsonì´ ëª¨ë‘ ìˆëŠ” ë‚ ì§œë“¤ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.

    Args:
        src_folder: Downloaded/{grp_name} í´ë” ê²½ë¡œ

    Returns:
        list: ì‚¬ìš© ê°€ëŠ¥í•œ ë‚ ì§œ ë¦¬ìŠ¤íŠ¸ (YYYYMMDD í˜•ì‹, ìµœì‹ ìˆœ ì •ë ¬)

    Example:
        dates = get_available_dates('./Downloaded/dsgeoadmin')
        # ['20260119', '20260113', '20260112']
    """
    baseinfo_dates = set()
    geojson_dates = set()

    date_pattern = re.compile(r'(baseinfo|geojson)(\d{8})')

    if not os.path.exists(src_folder):
        print(f"í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {src_folder}")
        return []

    for folder_name in os.listdir(src_folder):
        match = date_pattern.match(folder_name)
        if match:
            folder_type = match.group(1)
            date_str = match.group(2)

            if folder_type == 'baseinfo':
                baseinfo_dates.add(date_str)
            elif folder_type == 'geojson':
                geojson_dates.add(date_str)

    available_dates = sorted(baseinfo_dates & geojson_dates, reverse=True)

    print(f"=== Downloaded í´ë” ë¶„ì„ ===")
    print(f"baseinfo ë‚ ì§œ: {sorted(baseinfo_dates, reverse=True)}")
    print(f"geojson ë‚ ì§œ: {sorted(geojson_dates, reverse=True)}")
    print(f"ì‚¬ìš© ê°€ëŠ¥í•œ ë‚ ì§œ (ë‘˜ ë‹¤ ì¡´ì¬): {available_dates}")

    return available_dates


def upload_baseinfo_to_s3(src_folder: str, date_str: str) -> tuple:
    """
    ì§€ì •ëœ ë‚ ì§œì˜ baseinfo í´ë” ë‚´ìš©ì„ S3 dsbaseinfo ë²„í‚·ì— ì—…ë¡œë“œí•©ë‹ˆë‹¤.

    Args:
        src_folder: Downloaded/{grp_name} í´ë” ê²½ë¡œ
        date_str: ë‚ ì§œ ë¬¸ìì—´ (YYYYMMDD)

    Returns:
        tuple: (ì—…ë¡œë“œ ì„±ê³µ ìˆ˜, ì‹¤íŒ¨ ìˆ˜)

    Example:
        upload_baseinfo_to_s3('./Downloaded/dsgeoadmin', '20260112')
    """
    s3_client = boto3.client('s3')
    bucket_name = 'dsbaseinfo'

    baseinfo_folder = os.path.join(src_folder, f'baseinfo{date_str}')

    if not os.path.exists(baseinfo_folder):
        print(f"baseinfo í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {baseinfo_folder}")
        return (0, 0)

    uploaded_count = 0
    error_count = 0

    for root, dirs, files in os.walk(baseinfo_folder):
        for file in files:
            if file.endswith('.json'):
                local_path = os.path.join(root, file)
                relative_path = os.path.relpath(local_path, baseinfo_folder)
                s3_key = relative_path.replace('\\', '/')

                try:
                    s3_client.upload_file(local_path, bucket_name, s3_key)
                    print(f"Uploaded: {s3_key}")
                    uploaded_count += 1
                except ClientError as e:
                    print(f"Error uploading {local_path}: {e}")
                    error_count += 1

    print(f"\n=== baseinfo ì—…ë¡œë“œ ì™„ë£Œ ===")
    print(f"ì„±ê³µ: {uploaded_count}ê°œ, ì‹¤íŒ¨: {error_count}ê°œ")
    return (uploaded_count, error_count)


def upload_geojson_to_s3(src_folder: str, date_str: str, grp_name: str = 'dsgeoadmin') -> tuple:
    """
    ì§€ì •ëœ ë‚ ì§œì˜ geojson í´ë” ë‚´ìš©ì„ S3 dsgeousergrp ë²„í‚·ì— ì—…ë¡œë“œí•©ë‹ˆë‹¤.

    Args:
        src_folder: Downloaded/{grp_name} í´ë” ê²½ë¡œ
        date_str: ë‚ ì§œ ë¬¸ìì—´ (YYYYMMDD)
        grp_name: ê·¸ë£¹ëª… (ê¸°ë³¸ê°’: 'dsgeoadmin')

    Returns:
        tuple: (ì—…ë¡œë“œ ì„±ê³µ ìˆ˜, ì‹¤íŒ¨ ìˆ˜)

    Example:
        upload_geojson_to_s3('./Downloaded/dsgeoadmin', '20260112', 'dsgeoadmin')
    """
    s3_client = boto3.client('s3')
    bucket_name = 'dsgeousergrp'

    geojson_folder = os.path.join(src_folder, f'geojson{date_str}')

    if not os.path.exists(geojson_folder):
        print(f"geojson í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {geojson_folder}")
        return (0, 0)

    uploaded_count = 0
    error_count = 0

    for file in os.listdir(geojson_folder):
        if file.endswith('.json'):
            local_path = os.path.join(geojson_folder, file)
            s3_key = f"{grp_name}/coursegeojson/{file}"

            try:
                s3_client.upload_file(local_path, bucket_name, s3_key)
                print(f"Uploaded: {s3_key}")
                uploaded_count += 1
            except ClientError as e:
                print(f"Error uploading {local_path}: {e}")
                error_count += 1

    print(f"\n=== geojson ì—…ë¡œë“œ ì™„ë£Œ ===")
    print(f"ì„±ê³µ: {uploaded_count}ê°œ, ì‹¤íŒ¨: {error_count}ê°œ")
    return (uploaded_count, error_count)


def reset_to_date(src_folder: str, date_str: str, grp_name: str = 'dsgeoadmin'):
    """
    ì§€ì •ëœ ë‚ ì§œì˜ baseinfoì™€ geojsonì„ ëª¨ë‘ S3ì— ì—…ë¡œë“œí•˜ì—¬ í•´ë‹¹ ë‚ ì§œë¡œ ë¦¬ì…‹í•©ë‹ˆë‹¤.

    Args:
        src_folder: Downloaded/{grp_name} í´ë” ê²½ë¡œ
        date_str: ë‚ ì§œ ë¬¸ìì—´ (YYYYMMDD)
        grp_name: ê·¸ë£¹ëª… (ê¸°ë³¸ê°’: 'dsgeoadmin')

    Example:
        reset_to_date('./Downloaded/dsgeoadmin', '20260112', 'dsgeoadmin')
    """
    print(f"===== {date_str} ë‚ ì§œë¡œ ë¦¬ì…‹ ì‹œì‘ =====\n")

    print("[1/2] baseinfo ì—…ë¡œë“œ ì¤‘...")
    base_result = upload_baseinfo_to_s3(src_folder, date_str)
    print()

    print("[2/2] geojson ì—…ë¡œë“œ ì¤‘...")
    geo_result = upload_geojson_to_s3(src_folder, date_str, grp_name)
    print()

    print(f"===== {date_str} ë‚ ì§œë¡œ ë¦¬ì…‹ ì™„ë£Œ =====")
    print(f"ì´ ì—…ë¡œë“œ: baseinfo {base_result[0]}ê°œ, geojson {geo_result[0]}ê°œ")


def extract_types_from_geojson(geojson_path: str) -> list:
    """
    GeoJSON íŒŒì¼ì—ì„œ Type ì†ì„±ì˜ ê³ ìœ ê°’ë“¤ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.

    Args:
        geojson_path: GeoJSON íŒŒì¼ ê²½ë¡œ

    Returns:
        list: ì •ë ¬ëœ Type ê°’ ë¦¬ìŠ¤íŠ¸
    """
    try:
        with open(geojson_path, 'r', encoding='utf-8') as f:
            data = json.load(f)

        types_found = set()
        if 'features' in data:
            for feature in data['features']:
                if 'properties' in feature and 'Type' in feature['properties']:
                    types_found.add(feature['properties']['Type'])

        return sorted(list(types_found))
    except Exception as e:
        print(f"Error reading {geojson_path}: {e}")
        return []


def update_type_created_from_geojson(baseinfo_path: str, geojson_folder: str, prefix: str = None) -> list:
    """
    baseinfo JSONì˜ ê° í•­ëª©ì— ëŒ€í•´ í•´ë‹¹ geojsonì—ì„œ Typeì„ ì¶”ì¶œí•˜ì—¬ Type_createdë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.

    Args:
        baseinfo_path: baseinfo JSON íŒŒì¼ ê²½ë¡œ (ì˜ˆ: course_info.json)
        geojson_folder: geojson íŒŒì¼ë“¤ì´ ìˆëŠ” í´ë” ê²½ë¡œ
        prefix: ì²˜ë¦¬í•  id prefix (ì˜ˆ: 'TGC', 'MGC'). Noneì´ë©´ ëª¨ë‘ ì²˜ë¦¬

    Returns:
        list: ì—…ë°ì´íŠ¸ëœ baseinfo ë°ì´í„°

    Example:
        # TGCë§Œ ì²˜ë¦¬
        data = update_type_created_from_geojson(baseinfo_path, geojson_folder, prefix='TGC')
        # MGCë§Œ ì²˜ë¦¬
        data = update_type_created_from_geojson(baseinfo_path, geojson_folder, prefix='MGC')
        # ëª¨ë‘ ì²˜ë¦¬
        data = update_type_created_from_geojson(baseinfo_path, geojson_folder)
    """
    with open(baseinfo_path, 'r', encoding='utf-8') as f:
        baseinfo_data = json.load(f)

    updated_count = 0
    not_found_count = 0
    skipped_count = 0

    for obj in baseinfo_data:
        if 'id' not in obj:
            continue

        course_id = obj['id']

        # prefix í•„í„°ë§
        if prefix and not course_id.startswith(prefix):
            skipped_count += 1
            continue

        geojson_file = os.path.join(geojson_folder, f'{course_id}.json')

        if os.path.exists(geojson_file):
            types = extract_types_from_geojson(geojson_file)
            obj['Type_created'] = types
            updated_count += 1
        else:
            obj['Type_created'] = []
            not_found_count += 1
            print(f"  Geojson not found: {course_id}")

    # íŒŒì¼ ì €ì¥
    with open(baseinfo_path, 'w', encoding='utf-8') as f:
        json.dump(baseinfo_data, f, ensure_ascii=False, indent=2)

    print(f"=== Type_created ì—…ë°ì´íŠ¸ ì™„ë£Œ ({prefix or 'ALL'}) ===")
    print(f"ì—…ë°ì´íŠ¸: {updated_count}ê°œ, ë¯¸ë°œê²¬: {not_found_count}ê°œ, ìŠ¤í‚µ: {skipped_count}ê°œ")
    print(f"ì €ì¥: {baseinfo_path}")

    return baseinfo_data


def get_course_files(folder: str, prefix: str, min_num: int = 1, max_num: int = 899) -> list:
    """
    ì§€ì •ëœ prefixì™€ ë²ˆí˜¸ ë²”ìœ„ì— í•´ë‹¹í•˜ëŠ” GeoJSON íŒŒì¼ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤.

    Args:
        folder: GeoJSON íŒŒì¼ì´ ìˆëŠ” í´ë” ê²½ë¡œ
        prefix: íŒŒì¼ prefix (ì˜ˆ: 'MGC', 'TGC')
        min_num: ìµœì†Œ ë²ˆí˜¸ (ê¸°ë³¸ê°’: 1)
        max_num: ìµœëŒ€ ë²ˆí˜¸ (ê¸°ë³¸ê°’: 899)

    Returns:
        list: ì •ë ¬ëœ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸

    Example:
        mgc_files = get_course_files('./coursegeojson', 'MGC')  # MGC001~MGC899
        tgc_files = get_course_files('./coursegeojson', 'TGC', 1, 100)  # TGC001~TGC100
    """
    files = glob.glob(os.path.join(folder, f'{prefix}*.json'))
    result = []
    for f in files:
        basename = os.path.basename(f)
        try:
            num = int(basename.replace(prefix, '').replace('.json', ''))
            if min_num <= num <= max_num:
                result.append(f)
        except ValueError:
            continue
    return sorted(result)


def check_geojson_file(file_path: str, default_props: dict, unwanted_types: list = None) -> dict:
    """
    GeoJSON íŒŒì¼ì„ ê²€ì‚¬í•˜ì—¬ ë¬¸ì œì ì„ ë°˜í™˜í•©ë‹ˆë‹¤.

    Args:
        file_path: GeoJSON íŒŒì¼ ê²½ë¡œ
        default_props: ê¸°ë³¸ properties í…œí”Œë¦¿
        unwanted_types: í—ˆìš©ë˜ì§€ ì•ŠëŠ” Type ë¦¬ìŠ¤íŠ¸ (ê¸°ë³¸ê°’: ['Undefined', 'ê·¸ë¦°B'])

    Returns:
        dict: ê²€ì‚¬ ê²°ê³¼ (unwanted_types, missing_keys, type_mismatches, extra_keys, wrong_courseid)
    """
    from collections import defaultdict

    if unwanted_types is None:
        unwanted_types = ['Undefined', 'ê·¸ë¦°B']

    basename = os.path.basename(file_path)
    expected_courseid = basename.replace('.json', '')

    result = {
        'file': basename,
        'expected_courseid': expected_courseid,
        'feature_count': 0,
        'unwanted_types': defaultdict(int),
        'missing_keys': set(),
        'type_mismatches': defaultdict(set),
        'extra_keys': set(),
        'wrong_courseid': defaultdict(int),
    }

    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except Exception as e:
        result['error'] = str(e)
        return result

    features = data.get('features', [])
    result['feature_count'] = len(features)

    for feature in features:
        props = feature.get('properties', {})

        # 1. Unwanted Type ê²€ì‚¬
        feature_type = props.get('Type', '')
        if feature_type in unwanted_types:
            result['unwanted_types'][feature_type] += 1

        # 2. Missing Keys ê²€ì‚¬
        for key in default_props.keys():
            if key not in props:
                result['missing_keys'].add(key)

        # 3. Type Mismatches & Extra Keys ê²€ì‚¬
        for key, value in props.items():
            if key in default_props:
                expected_type = type(default_props[key])
                actual_type = type(value)
                if expected_type != actual_type:
                    result['type_mismatches'][key].add(
                        f"{actual_type.__name__} (expected: {expected_type.__name__})"
                    )
            else:
                result['extra_keys'].add(key)

        # 4. mapdscourseid ê²€ì‚¬
        mapdscourseid = props.get('mapdscourseid', '')
        if mapdscourseid != expected_courseid:
            result['wrong_courseid'][mapdscourseid] += 1

    return result


def check_geojson_files(folder: str, default_props: dict = None, unwanted_types: list = None, prefixes: list = None, save_report: str = None):
    """
    í´ë” ë‚´ ëª¨ë“  GeoJSON íŒŒì¼ì„ ê²€ì‚¬í•˜ê³  ê²°ê³¼ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.

    Args:
        folder: GeoJSON íŒŒì¼ì´ ìˆëŠ” í´ë” ê²½ë¡œ
        default_props: ê¸°ë³¸ properties í…œí”Œë¦¿ (Noneì´ë©´ ìë™ ë¡œë“œ)
        unwanted_types: í—ˆìš©ë˜ì§€ ì•ŠëŠ” Type ë¦¬ìŠ¤íŠ¸
        prefixes: ê²€ì‚¬í•  prefix ë¦¬ìŠ¤íŠ¸ (ê¸°ë³¸ê°’: ['MGC', 'TGC'])
        save_report: ê²°ê³¼ë¥¼ ì €ì¥í•  íŒŒì¼ ê²½ë¡œ (Noneì´ë©´ ì €ì¥ ì•ˆí•¨)

    Returns:
        tuple: (all_results, problem_results)
    """
    from datetime import datetime

    if default_props is None:
        default_props = load_default_feature_properties()
    if unwanted_types is None:
        unwanted_types = ['Undefined', 'ê·¸ë¦°B']
    if prefixes is None:
        prefixes = ['MGC', 'TGC']

    # íŒŒì¼ ìˆ˜ì§‘
    all_files = []
    file_counts = {}
    for prefix in prefixes:
        files = get_course_files(folder, prefix)
        file_counts[prefix] = len(files)
        all_files.extend(files)

    print(f"ê²€ì‚¬ ëŒ€ìƒ: {' + '.join([f'{p}: {file_counts[p]}ê°œ' for p in prefixes])} = ì´ {len(all_files)}ê°œ")

    # ê²€ì‚¬ ì‹¤í–‰
    all_results = []
    for file_path in all_files:
        result = check_geojson_file(file_path, default_props, unwanted_types)
        all_results.append(result)

    # ë¬¸ì œ ìˆëŠ” ê²°ê³¼ í•„í„°ë§
    def has_problems(r):
        return (r.get('error') or r['unwanted_types'] or r['missing_keys'] or
                r['type_mismatches'] or r['extra_keys'] or r['wrong_courseid'])

    problem_results = [r for r in all_results if has_problems(r)]

    # ì¶œë ¥ ë° ë¦¬í¬íŠ¸ ìƒì„±
    report_lines = []
    report_lines.append(f"GeoJSON ê²€ì‚¬ ë¦¬í¬íŠ¸ - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    report_lines.append(f"ê²€ì‚¬ ëŒ€ìƒ: {' + '.join([f'{p}: {file_counts[p]}ê°œ' for p in prefixes])} = ì´ {len(all_files)}ê°œ")
    report_lines.append("")

    # ë¬¸ì œ ìˆëŠ” íŒŒì¼ ìƒì„¸ ì¶œë ¥
    if problem_results:
        print(f"\n=== ë¬¸ì œê°€ ìˆëŠ” íŒŒì¼: {len(problem_results)}ê°œ ===\n")
        report_lines.append(f"=== ë¬¸ì œê°€ ìˆëŠ” íŒŒì¼: {len(problem_results)}ê°œ ===")
        report_lines.append("")

        for result in problem_results:
            line = f"ğŸ“ {result['file']} (Features: {result['feature_count']})"
            print(line)
            report_lines.append(line)

            if result.get('error'):
                line = f"  âŒ Error: {result['error']}"
                print(line + "\n")
                report_lines.append(line)
                report_lines.append("")
                continue

            if result['unwanted_types']:
                line = f"  âš ï¸ Unwanted Types: {dict(result['unwanted_types'])}"
                print(line)
                report_lines.append(line)
            if result['missing_keys']:
                line = f"  âŒ Missing Keys: {sorted(result['missing_keys'])}"
                print(line)
                report_lines.append(line)
            if result['type_mismatches']:
                line = f"  âŒ Type Mismatches: {dict((k, sorted(v)) for k, v in result['type_mismatches'].items())}"
                print(line)
                report_lines.append(line)
            if result['extra_keys']:
                line = f"  âš ï¸ Extra Keys: {sorted(result['extra_keys'])}"
                print(line)
                report_lines.append(line)
            if result['wrong_courseid']:
                line = f"  âŒ Wrong mapdscourseid: {dict(result['wrong_courseid'])}"
                print(line)
                report_lines.append(line)
            print()
            report_lines.append("")

    # ìµœì¢… ìš”ì•½
    total_features = sum(r['feature_count'] for r in all_results)
    summary_lines = [
        "=" * 50,
        "                   ìµœì¢… ìš”ì•½",
        "=" * 50,
        f"ê²€ì‚¬ íŒŒì¼: {len(all_results)}ê°œ, ì´ Features: {total_features}ê°œ",
        f"ë¬¸ì œ ìˆëŠ” íŒŒì¼: {len(problem_results)}ê°œ"
    ]

    if problem_results:
        summary_lines.extend([
            f"  - Unwanted Types: {sum(1 for r in all_results if r['unwanted_types'])}ê°œ",
            f"  - Missing Keys: {sum(1 for r in all_results if r['missing_keys'])}ê°œ",
            f"  - Type Mismatches: {sum(1 for r in all_results if r['type_mismatches'])}ê°œ",
            f"  - Extra Keys: {sum(1 for r in all_results if r['extra_keys'])}ê°œ",
            f"  - Wrong mapdscourseid: {sum(1 for r in all_results if r['wrong_courseid'])}ê°œ"
        ])
    else:
        summary_lines.append("âœ… ëª¨ë“  íŒŒì¼ì´ ì •ìƒì…ë‹ˆë‹¤!")

    for line in summary_lines:
        print(line)
        report_lines.append(line)

    # íŒŒì¼ë¡œ ì €ì¥
    if save_report:
        with open(save_report, 'w', encoding='utf-8') as f:
            f.write('\n'.join(report_lines))
        print(f"\nğŸ“„ ë¦¬í¬íŠ¸ ì €ì¥: {save_report}")

    return all_results, problem_results


def parse_geojson_report(report_path: str) -> list:
    """
    CRS-0ì—ì„œ ìƒì„±ëœ ë¦¬í¬íŠ¸ íŒŒì¼ì„ íŒŒì‹±í•˜ì—¬ ë¬¸ì œê°€ ìˆëŠ” ì½”ìŠ¤ ID ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

    Args:
        report_path: ë¦¬í¬íŠ¸ íŒŒì¼ ê²½ë¡œ

    Returns:
        list: ë¬¸ì œê°€ ìˆëŠ” ì½”ìŠ¤ ID ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: ['MGC001', 'TGC002'])

    Example:
        problem_ids = parse_geojson_report('./Reports/geojson_check_20260120.txt')
    """
    problem_ids = []

    with open(report_path, 'r', encoding='utf-8') as f:
        for line in f:
            # ğŸ“ MGC001.json (Features: 123) í˜•ì‹ íŒŒì‹±
            if line.strip().startswith('ğŸ“'):
                match = re.search(r'ğŸ“\s+(\w+)\.json', line)
                if match:
                    problem_ids.append(match.group(1))

    return problem_ids


def fix_geojson_file(file_path: str, default_props: dict = None, unwanted_types: list = None) -> dict:
    """
    GeoJSON íŒŒì¼ì˜ ë¬¸ì œë¥¼ ìˆ˜ì •í•©ë‹ˆë‹¤.

    ìˆ˜ì • í•­ëª©:
    1. Unwanted Types: í•´ë‹¹ feature ì‚­ì œ
    2. Missing Keys: ê¸°ë³¸ê°’ìœ¼ë¡œ ì¶”ê°€
    3. Extra Keys: ì œê±°
    4. Type Mismatches: ì˜¬ë°”ë¥¸ íƒ€ì…ìœ¼ë¡œ ë³€í™˜
    5. Wrong mapdscourseid: íŒŒì¼ëª… ê¸°ì¤€ìœ¼ë¡œ ìˆ˜ì •

    Args:
        file_path: GeoJSON íŒŒì¼ ê²½ë¡œ
        default_props: ê¸°ë³¸ properties í…œí”Œë¦¿ (Noneì´ë©´ ìë™ ë¡œë“œ)
        unwanted_types: ì‚­ì œí•  Type ë¦¬ìŠ¤íŠ¸ (ê¸°ë³¸ê°’: ['Undefined', 'ê·¸ë¦°B'])

    Returns:
        dict: ìˆ˜ì • ê²°ê³¼ ìš”ì•½

    Example:
        result = fix_geojson_file('./coursegeojson/MGC001.json')
        result = fix_geojson_file('./coursegeojson/MGC001.json', unwanted_types=['Undefined', 'ê·¸ë¦°B'])
    """
    if default_props is None:
        default_props = load_default_feature_properties()

    if unwanted_types is None:
        unwanted_types = ['Undefined', 'ê·¸ë¦°B']

    basename = os.path.basename(file_path)
    expected_courseid = basename.replace('.json', '')

    result = {
        'file': basename,
        'deleted_features': 0,
        'fixed_missing_keys': 0,
        'fixed_extra_keys': 0,
        'fixed_type_mismatches': 0,
        'fixed_wrong_courseid': 0,
    }

    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except Exception as e:
        result['error'] = str(e)
        return result

    features = data.get('features', [])
    original_count = len(features)

    # 1. Unwanted Types feature ì‚­ì œ
    filtered_features = []
    for feature in features:
        props = feature.get('properties', {})
        feature_type = props.get('Type', '')
        if feature_type in unwanted_types:
            result['deleted_features'] += 1
        else:
            filtered_features.append(feature)

    # ë‚¨ì€ features ì²˜ë¦¬
    for feature in filtered_features:
        props = feature.get('properties', {})

        # 2. Wrong mapdscourseid ìˆ˜ì •
        if props.get('mapdscourseid', '') != expected_courseid:
            props['mapdscourseid'] = expected_courseid
            result['fixed_wrong_courseid'] += 1

        # 3. Missing Keys ì¶”ê°€ ë° Type Mismatches ìˆ˜ì •
        for key, default_value in default_props.items():
            if key not in props:
                props[key] = default_value.copy() if isinstance(default_value, list) else default_value
                result['fixed_missing_keys'] += 1
            else:
                # Type mismatch ìˆ˜ì •
                expected_type = type(default_value)
                if not isinstance(props[key], expected_type):
                    try:
                        if expected_type == list:
                            if isinstance(props[key], str):
                                props[key] = json.loads(props[key])
                            else:
                                props[key] = list(props[key]) if props[key] else default_value.copy()
                        elif expected_type == float:
                            props[key] = float(props[key])
                        elif expected_type == int:
                            props[key] = int(props[key])
                        elif expected_type == str:
                            props[key] = str(props[key])
                        result['fixed_type_mismatches'] += 1
                    except (ValueError, TypeError, json.JSONDecodeError):
                        props[key] = default_value.copy() if isinstance(default_value, list) else default_value
                        result['fixed_type_mismatches'] += 1

        # 4. Extra Keys ì œê±°
        extra_keys = [k for k in props.keys() if k not in default_props]
        for key in extra_keys:
            del props[key]
            result['fixed_extra_keys'] += 1

        feature['properties'] = props

    # features ì—…ë°ì´íŠ¸
    data['features'] = filtered_features

    # íŒŒì¼ ì €ì¥
    with open(file_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

    return result


def fix_geojsons_from_report(report_path: str, geojson_folder: str, default_props: dict = None, unwanted_types: list = None) -> list:
    """
    ë¦¬í¬íŠ¸ íŒŒì¼ì„ ì½ì–´ ë¬¸ì œê°€ ìˆëŠ” GeoJSON íŒŒì¼ë“¤ì„ ìˆ˜ì •í•©ë‹ˆë‹¤.

    Args:
        report_path: CRS-0ì—ì„œ ìƒì„±ëœ ë¦¬í¬íŠ¸ íŒŒì¼ ê²½ë¡œ
        geojson_folder: GeoJSON íŒŒì¼ë“¤ì´ ìˆëŠ” í´ë” ê²½ë¡œ
        default_props: ê¸°ë³¸ properties í…œí”Œë¦¿ (Noneì´ë©´ ìë™ ë¡œë“œ)
        unwanted_types: ì‚­ì œí•  Type ë¦¬ìŠ¤íŠ¸ (ê¸°ë³¸ê°’: ['Undefined', 'ê·¸ë¦°B'])

    Returns:
        list: ê° íŒŒì¼ë³„ ìˆ˜ì • ê²°ê³¼ ë¦¬ìŠ¤íŠ¸

    Example:
        results = fix_geojsons_from_report(
            './Reports/geojson_check_20260120.txt',
            './ToUpload/dsgeoadmin/coursegeojson'
        )
    """
    if default_props is None:
        default_props = load_default_feature_properties()

    if unwanted_types is None:
        unwanted_types = ['Undefined', 'ê·¸ë¦°B']

    # ë¦¬í¬íŠ¸ì—ì„œ ë¬¸ì œ ìˆëŠ” ì½”ìŠ¤ ID íŒŒì‹±
    problem_ids = parse_geojson_report(report_path)

    if not problem_ids:
        print("ë¦¬í¬íŠ¸ì—ì„œ ë¬¸ì œê°€ ìˆëŠ” íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return []

    print(f"=== ìˆ˜ì • ëŒ€ìƒ: {len(problem_ids)}ê°œ íŒŒì¼ ===")
    print(f"ì½”ìŠ¤ ID: {problem_ids}\n")

    results = []
    total_deleted = 0

    for course_id in problem_ids:
        file_path = os.path.join(geojson_folder, f'{course_id}.json')

        if not os.path.exists(file_path):
            print(f"âš ï¸ íŒŒì¼ ì—†ìŒ: {file_path}")
            results.append({'file': f'{course_id}.json', 'error': 'File not found'})
            continue

        result = fix_geojson_file(file_path, default_props, unwanted_types)
        results.append(result)

        # ìˆ˜ì • ê²°ê³¼ ì¶œë ¥
        deleted = result.get('deleted_features', 0)
        total_deleted += deleted
        total_fixes = (result.get('fixed_missing_keys', 0) +
                      result.get('fixed_extra_keys', 0) +
                      result.get('fixed_type_mismatches', 0) +
                      result.get('fixed_wrong_courseid', 0))

        if result.get('error'):
            print(f"âŒ {result['file']}: {result['error']}")
        elif deleted > 0 or total_fixes > 0:
            msg = f"âœ… {result['file']}:"
            if deleted > 0:
                msg += f" {deleted}ê°œ feature ì‚­ì œ"
            if total_fixes > 0:
                msg += f" {total_fixes}ê°œ ìˆ˜ì •"
            print(msg)
        else:
            print(f"âœ“ {result['file']}: ìˆ˜ì • ë¶ˆí•„ìš”")

    # ìµœì¢… ìš”ì•½
    print(f"\n=== ìˆ˜ì • ì™„ë£Œ ===")
    total_files = len([r for r in results if not r.get('error')])
    print(f"ì²˜ë¦¬ íŒŒì¼: {total_files}ê°œ")
    if total_deleted > 0:
        print(f"ì‚­ì œëœ feature ì´: {total_deleted}ê°œ")

    return results